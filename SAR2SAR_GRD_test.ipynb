{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "SAR2SAR_GRD_test.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**[Download the notebook](https://gitlab.telecom-paris.fr/ring/sar2sar/-/raw/master/SAR2SAR_GRD_test.ipynb?inline=false) and then import it under Google Colab**\n",
    "\n",
    "<a href=\"https://colab.research.google.com/\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a94OoNwSB4K8"
   },
   "source": [
    "# SAR2SAR: a self-supervised despeckling algorithm for SAR images\n",
    "## Emanuele Dalsasso, Loïc Denis, Florence Tupin\n",
    "\n",
    "Please note that the training set is only composed of **GRD** SAR images, thus this testing code is specific to this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "V7SJyBmKrSIH"
   },
   "source": [
    "## Resources\n",
    "- [Paper (ArXiv)](https://arxiv.org/abs/2006.15037)\n",
    "\n",
    "To cite the article:\n",
    "\n",
    "    @article{dalsasso2020sar2sar,\n",
    "        title={{SAR2SAR}: a self-supervised despeckling algorithm for {SAR} images},\n",
    "        author={Emanuele Dalsasso and Loïc Denis and Florence Tupin},\n",
    "        journal={arXiv preprint arXiv:2006.15037},\n",
    "        year={2020}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ugjl3KuDKwQ"
   },
   "source": [
    "## 0. Enable GPU and save copy on Drive to enable editing\n",
    "Runtime -> Change runtime type -> Hardware accelerator: GPU\n",
    "\n",
    "File -> Save a copy in Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBSypL94C9L3"
   },
   "source": [
    "## 1. Download network weights and code"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Fn6fXbssdjm4"
   },
   "source": [
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "gdd.download_file_from_google_drive(file_id='1U8UT87k1AmiKhgE-fSkqSq5xmv32pOnu',\n",
    "                                    dest_path='./SAR2SAR-GRD-test.zip',\n",
    "                                    unzip=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Faq_Z-9TDboL"
   },
   "source": [
    "## 2. Install compatible version of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qt7gNr5n0Rf_"
   },
   "source": [
    "!pip uninstall -y tensorflow"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fnC1KRKBiubW"
   },
   "source": [
    "!pip install tensorflow-gpu==1.13.1"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJfhq_QbGvkg"
   },
   "source": [
    "## 3. Test on real data\n",
    "Some **GRD** images in **amplitude** format can be found in the folder _/content/SAR2SAR-GRD-test/test_data/_\n",
    "\n",
    "\n",
    "To test on custom data, upload your single channel GRD images in a numpy array with shape [ydim, xdim] in the folder _/content/SAR2SAR-GRD-test/test_data/_\n",
    "\n",
    "Results are stored in _/content/test_\n",
    "\n",
    "At each time a test is run, clean the _/content/test_ directory otherwise the results will be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tBownFrNEU5R"
   },
   "source": [
    "!python /content/SAR2SAR-GRD-test/main.py "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZTikzYaR0zh"
   },
   "source": [
    "When image dimension exeeds 256, the U-Net is scanned over the image with a default stride of 64 pixels. To change it to a custom value, run the cell below (here it is set to 32, allowing more quality at the cost of a greater runtime)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JdSva30cNp75"
   },
   "source": [
    "!python /content/SAR2SAR-GRD-test/main.py --stride_size=32"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}